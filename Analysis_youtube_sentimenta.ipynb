{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jesustellez/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data management\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "#FOR PROCESSING\n",
    "import nltk\n",
    "import re\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "#FORR W2V\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "#FOR PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#FOR BERT MODEL -> TO STUDY BERT MODEL\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TIME SERIES WITH #VIDEOS, LIKES, COMMENTS \"\"\"\n",
    "\n",
    "class EDA_Analysis():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        def data_read_csv(path, title):\n",
    "            video = path + \"/\" + title\n",
    "            df_ = pd.read_csv(video)\n",
    "\n",
    "            return df_\n",
    "\n",
    "        path = \"/Users/jesustellez/Desktop/aiDynamics/API Data extraction/Data\"\n",
    "        df_comments = data_read_csv(path, \"comments_eeuu.csv\")\n",
    "        self.df_comments = df_comments\n",
    "        df_videos = data_read_csv(path, \"videos_eeuu.csv\")\n",
    "        df_videos[\"Date\"] = df_videos[\"publishedAt\"].str.split(\"T\", expand=True)[0]\n",
    "        self.df_videos = df_videos\n",
    "        df_calendar = data_read_csv(path, \"calendar.csv\")\n",
    "        df_calendar[\"Week-Year\"] = df_calendar[\"Week\"].astype(str) + \"-\" + df_calendar[\"Year\"].astype(str)\n",
    "        self.df_calendar = df_calendar\n",
    "\n",
    "    def __returndata__(self):\n",
    "        return self.df_videos, self.df_calendar, self.df_comments\n",
    "    \n",
    "    def EDA_timely(self, period):\n",
    "\n",
    "        df_ts_analysis = self.df_videos.merge(\n",
    "            self.df_calendar[[\"Date\", \"Day\", \"Week\",\"Month\", \"Month-Year\", \"Week-Year\"]], \n",
    "            on=\"Date\", \n",
    "            how=\"left\")\n",
    "        \n",
    "        df_ts_analysis_wy = df_ts_analysis.groupby(period, as_index=False).agg({\"viewCount\":\"sum\", \"video_id\":\"count\",\"commentCount\":\"sum\"})\n",
    "        return df_ts_analysis_wy\n",
    "\n",
    "    def EDA_time_graph(self, period, fields, df_analysis):\n",
    "\n",
    "        fig = go.Figure()\n",
    "        for i in fields:\n",
    "            fig.add_trace(go.Scatter(x=df_analysis[period], y=df_analysis[i]))\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "df_videos, df_calendar, df_comments = EDA_Analysis().__returndata__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "THIS FIRST PART I AM GOING TO REDUCE THE NUMBER OF TAGS TO TRY TO CORRELATE THE VIDEOS WITH TOPICS (IN EXAMPLE, WAR, POLITICS, TECHNOLOGY, ETC)\n",
    "\"\"\"\n",
    "def clean_tags(text, flg_stemm = False, flg_lemm=True, lst_stopwords = None):\n",
    "    ## Clean (convert to lowercase and remove punctuation and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower())\n",
    "\n",
    "    ## Tolenize (Convert from string to List)\n",
    "    lst_text = text.split()\n",
    "\n",
    "    ## Remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in lst_stopwords]\n",
    "\n",
    "    ## Stemming (to remove -ly, -ing, etc.)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "    ## Lemmatisation (Convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\n",
    "    ## Back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPROCESSING OF DATA SET\n",
    "df_videos[\"tags\"] = df_videos.tags.str.split(\",\")\n",
    "df_videos = df_videos.explode(\"tags\")\n",
    "\n",
    "## CREATION OF STOPWORDS WITH NLTK LIBRARY\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "df_videos[\"tags_clean\"] = df_videos[\"tags\"].apply(lambda x: clean_tags(\n",
    "    x,\n",
    "    flg_stemm=False,\n",
    "    flg_lemm=True,\n",
    "    lst_stopwords=lst_stopwords\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1917 espionage act', '1918 sedition act', 'news', ...,\n",
       "       'jared polis', 'middle fork fire', 'new year fire'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos.tags_clean.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1cbc4bc2cb2f84e1561c66ade6c5819f38a88dcb1bb01c0e10107a42dfff19b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
